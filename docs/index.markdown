---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

---


# Tutorial on Deep Learning for HAR


## INTRODUCTION

### Why this tutorial? 
Activity recognition systems that are capable of estimating human activities from wearable inertial sensors have come a long way in the past decades. Not only have state-of-the-art methods moved away from feature engineering and have fully adopted end-to-end deep learning approaches, best practices for setting up experiments, preparing datasets, and validating activity recognition approaches have similarly evolved.
This new tutorial will, after a short introduction in the research field of activity recognition, provide a hands-on and interactive walk-through of the most important steps in the data pipeline for the deep learning of human activities.
### How to use this GitHub page?
This tutorial is structured into three main parts. 

First, we will give an introduction to the field of Human Activity Recognition (HAR), as well as what you can expect from this tutorial.

Second, we will introduce to you the Deep Learning Activity Recognition Chain (DL-ARC) pipeline which is an updated version of the Activity Recognition Chain as proposed by Bulling et al. [[1]](#1). 

## THEORETICAL BACKGROUND

### What is Human Activity Recognition (HAR)?

### Why Deep Learning?

### DeepConvLSTM architecture

### RealWorld HAR Dataset

## THE DL-ARC PIPELINE

### Data Collection

### Data Analysis

### Preprocessing

### Training

#### Cross-Validation

### Evaluation

## IMPROVING YOUR RESULTS

## REFERENCES
<a id="1">[1]</a>
Andreas Bulling, Ulf Blanke, and Bernt Schiele. 2014.  A Tutorial on Human Activity Recognition Using Body-Worn Inertial Sensors. Comput. Surveys 46, 3 (2014). https://doi.org/10.1145/2499621

